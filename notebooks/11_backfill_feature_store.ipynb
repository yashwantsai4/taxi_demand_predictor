{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "HOPSWORKS_PROJECT_NAME='NYC_Taxi_Prediction'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir('..')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from src.paths import PARENT_DIR\n",
    "\n",
    "\n",
    "# load key-value pairs from .env file located in the parent directory\n",
    "load_dotenv(PARENT_DIR / '.env')\n",
    "\n",
    "HOPSWORKS_API_KEY = os.environ['HOPSWORKS_API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading raw data from 2022 to 2024\n",
      "File 2022-01 was already in local storage\n",
      "File 2022-02 was already in local storage\n",
      "File 2022-03 was already in local storage\n",
      "File 2022-04 was already in local storage\n",
      "File 2022-05 was already in local storage\n",
      "File 2022-06 was already in local storage\n",
      "File 2022-07 was already in local storage\n",
      "File 2022-08 was already in local storage\n",
      "File 2022-09 was already in local storage\n",
      "File 2022-10 was already in local storage\n",
      "File 2022-11 was already in local storage\n",
      "File 2022-12 was already in local storage\n",
      "File 2023-01 was already in local storage\n",
      "File 2023-02 was already in local storage\n",
      "File 2023-03 was already in local storage\n",
      "File 2023-04 was already in local storage\n",
      "File 2023-05 was already in local storage\n",
      "File 2023-06 was already in local storage\n",
      "File 2023-07 was already in local storage\n",
      "File 2023-08 was already in local storage\n",
      "File 2023-09 was already in local storage\n",
      "File 2023-10 was already in local storage\n",
      "File 2023-11 was already in local storage\n",
      "Downloading file 2023-12\n",
      "2023-12 file is not available\n",
      "Downloading file 2024-01\n",
      "2024-01 file is not available\n",
      "Downloading file 2024-02\n",
      "2024-02 file is not available\n",
      "Downloading file 2024-03\n",
      "2024-03 file is not available\n",
      "Downloading file 2024-04\n",
      "2024-04 file is not available\n",
      "Downloading file 2024-05\n",
      "2024-05 file is not available\n",
      "Downloading file 2024-06\n",
      "2024-06 file is not available\n",
      "Downloading file 2024-07\n",
      "2024-07 file is not available\n",
      "Downloading file 2024-08\n",
      "2024-08 file is not available\n",
      "Downloading file 2024-09\n",
      "2024-09 file is not available\n",
      "Downloading file 2024-10\n",
      "2024-10 file is not available\n",
      "Downloading file 2024-11\n",
      "2024-11 file is not available\n",
      "Downloading file 2024-12\n",
      "2024-12 file is not available\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "from src.data import load_raw_data\n",
    "\n",
    "from_year = 2022\n",
    "to_year = datetime.now().year\n",
    "print(f'Downloading raw data from {from_year} to {to_year}')\n",
    "\n",
    "rides = pd.DataFrame()\n",
    "for year in range(from_year, to_year+1):\n",
    "    \n",
    "    # download data for the whole year\n",
    "    rides_one_year = load_raw_data(year)\n",
    "    \n",
    "    # append rows\n",
    "    rides = pd.concat([rides, rides_one_year])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(rides)=74,587,606\n"
     ]
    }
   ],
   "source": [
    "print(f'{len(rides)=:,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 265/265 [00:05<00:00, 44.32it/s]\n"
     ]
    }
   ],
   "source": [
    "from src.data import transform_raw_data_into_ts_data\n",
    "\n",
    "ts_data = transform_raw_data_into_ts_data(rides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# string to datetime\n",
    "ts_data['pickup_hour'] = pd.to_datetime(ts_data['pickup_hour'], utc=True)\n",
    "\n",
    "# add column with Unix epoch milliseconds\n",
    "ts_data['pickup_ts'] = ts_data['pickup_hour'].astype(int) // 10**6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yashwantsaikoneru/opt/anaconda3/envs/conda_environment/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import hopsworks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected. Call `.close()` to terminate connection gracefully.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/453781\n"
     ]
    }
   ],
   "source": [
    "project = hopsworks.login(\n",
    "    project=HOPSWORKS_PROJECT_NAME,\n",
    "    api_key_value=HOPSWORKS_API_KEY\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected. Call `.close()` to terminate connection gracefully.\n"
     ]
    }
   ],
   "source": [
    "feature_store = project.get_feature_store()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURE_GROUP_NAME = 'time_series_hourly_feature_group'\n",
    "FEATURE_GROUP_VERSION = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_group = feature_store.get_or_create_feature_group(\n",
    "    name=FEATURE_GROUP_NAME,\n",
    "    version=FEATURE_GROUP_VERSION,\n",
    "    description=\"Time-series data at hourly frequency\",\n",
    "    primary_key = ['pickup_location_id', 'pickup_hour'],\n",
    "    event_time='pickup_hour',\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "Uploading Dataframe: 1.07% |          | Rows 47371/4445640 | Elapsed Time: 00:04 | Remaining Time: 04:56 "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mfeature_group\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minsert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mts_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwrite_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwait_for_job\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/conda_environment/lib/python3.9/site-packages/hsfs/feature_group.py:1984\u001b[0m, in \u001b[0;36mFeatureGroup.insert\u001b[0;34m(self, features, overwrite, operation, storage, write_options, validation_options, save_code, wait)\u001b[0m\n\u001b[1;32m   1981\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwait_for_job\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m write_options:\n\u001b[1;32m   1982\u001b[0m     write_options[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwait_for_job\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m wait\n\u001b[0;32m-> 1984\u001b[0m job, ge_report \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_feature_group_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minsert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1985\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1986\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeature_dataframe\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_dataframe\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1987\u001b[0m \u001b[43m    \u001b[49m\u001b[43moverwrite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1988\u001b[0m \u001b[43m    \u001b[49m\u001b[43moperation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moperation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1989\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlower\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1990\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwrite_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwrite_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1991\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msave_report\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mvalidation_options\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1992\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1993\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m save_code \u001b[38;5;129;01mand\u001b[39;00m (\n\u001b[1;32m   1994\u001b[0m     ge_report \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m ge_report\u001b[38;5;241m.\u001b[39mingestion_result \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mINGESTED\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1995\u001b[0m ):\n\u001b[1;32m   1996\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_code_engine\u001b[38;5;241m.\u001b[39msave_code(\u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/conda_environment/lib/python3.9/site-packages/hsfs/core/feature_group_engine.py:124\u001b[0m, in \u001b[0;36mFeatureGroupEngine.insert\u001b[0;34m(self, feature_group, feature_dataframe, overwrite, operation, storage, write_options, validation_options)\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m overwrite:\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_feature_group_api\u001b[38;5;241m.\u001b[39mdelete_content(feature_group)\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m--> 124\u001b[0m     \u001b[43mengine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_instance\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_dataframe\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfeature_group\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfeature_dataframe\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbulk_insert\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moverwrite\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moperation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfeature_group\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43monline_enabled\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    129\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[43m        \u001b[49m\u001b[43moffline_write_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    131\u001b[0m \u001b[43m        \u001b[49m\u001b[43monline_write_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    132\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    133\u001b[0m     ge_report,\n\u001b[1;32m    134\u001b[0m )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/conda_environment/lib/python3.9/site-packages/hsfs/engine/python.py:495\u001b[0m, in \u001b[0;36mEngine.save_dataframe\u001b[0;34m(self, feature_group, dataframe, operation, online_enabled, storage, offline_write_options, online_write_options, validation_id)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msave_dataframe\u001b[39m(\n\u001b[1;32m    481\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    482\u001b[0m     feature_group: FeatureGroup,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    489\u001b[0m     validation_id: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    490\u001b[0m ):\n\u001b[1;32m    491\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    492\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(feature_group, ExternalFeatureGroup)\n\u001b[1;32m    493\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m feature_group\u001b[38;5;241m.\u001b[39monline_enabled\n\u001b[1;32m    494\u001b[0m     ) \u001b[38;5;129;01mor\u001b[39;00m feature_group\u001b[38;5;241m.\u001b[39mstream:\n\u001b[0;32m--> 495\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_write_dataframe_kafka\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfeature_group\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moffline_write_options\u001b[49m\n\u001b[1;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    498\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    499\u001b[0m         \u001b[38;5;66;03m# for backwards compatibility\u001b[39;00m\n\u001b[1;32m    500\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlegacy_save_dataframe(\n\u001b[1;32m    501\u001b[0m             feature_group,\n\u001b[1;32m    502\u001b[0m             dataframe,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    508\u001b[0m             validation_id,\n\u001b[1;32m    509\u001b[0m         )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/conda_environment/lib/python3.9/site-packages/hsfs/engine/python.py:1004\u001b[0m, in \u001b[0;36mEngine._write_dataframe_kafka\u001b[0;34m(self, feature_group, dataframe, offline_write_options)\u001b[0m\n\u001b[1;32m   1001\u001b[0m         encoded_row \u001b[38;5;241m=\u001b[39m outf\u001b[38;5;241m.\u001b[39mgetvalue()\n\u001b[1;32m   1003\u001b[0m     \u001b[38;5;66;03m# assemble key\u001b[39;00m\n\u001b[0;32m-> 1004\u001b[0m     key \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([\u001b[38;5;28mstr\u001b[39m(row[pk]) \u001b[38;5;28;01mfor\u001b[39;00m pk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(feature_group\u001b[38;5;241m.\u001b[39mprimary_key)])\n\u001b[1;32m   1006\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_kafka_produce(\n\u001b[1;32m   1007\u001b[0m         producer, feature_group, key, encoded_row, acked, offline_write_options\n\u001b[1;32m   1008\u001b[0m     )\n\u001b[1;32m   1010\u001b[0m \u001b[38;5;66;03m# make sure producer blocks and everything is delivered\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/conda_environment/lib/python3.9/site-packages/hsfs/engine/python.py:1004\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1001\u001b[0m         encoded_row \u001b[38;5;241m=\u001b[39m outf\u001b[38;5;241m.\u001b[39mgetvalue()\n\u001b[1;32m   1003\u001b[0m     \u001b[38;5;66;03m# assemble key\u001b[39;00m\n\u001b[0;32m-> 1004\u001b[0m     key \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[43mpk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m pk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(feature_group\u001b[38;5;241m.\u001b[39mprimary_key)])\n\u001b[1;32m   1006\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_kafka_produce(\n\u001b[1;32m   1007\u001b[0m         producer, feature_group, key, encoded_row, acked, offline_write_options\n\u001b[1;32m   1008\u001b[0m     )\n\u001b[1;32m   1010\u001b[0m \u001b[38;5;66;03m# make sure producer blocks and everything is delivered\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading Dataframe: 1.96% |▏         | Rows 87007/4445640 | Elapsed Time: 00:16 | Remaining Time: 04:54"
     ]
    }
   ],
   "source": [
    "feature_group.insert(ts_data, write_options={\"wait_for_job\": False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_environment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
